{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkOpMiCBcWGd7C2IO8/VUA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GPapadakis77/ai_tax_opportunity_identifier/blob/main/ai_tax_opportunity_identifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Σύνδεση με Google Drive & Δημιουργία Βασικής Δομής Project"
      ],
      "metadata": {
        "id": "g3pgpGXmefgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"Συνδέομαι με το Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Σύνδεση με το Google Drive ολοκληρώθηκε.\")\n",
        "\n",
        "base_project_path = '/content/drive/My Drive/AI_Tax_Opportunity_Identifier'\n",
        "try:\n",
        "    os.makedirs(base_project_path, exist_ok=True)\n",
        "    print(f\"Δημιουργήθηκε (ή υπάρχει ήδη) ο βασικός φάκελος project στο: {base_project_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Σφάλμα κατά τη δημιουργία του φακέλου project: {e}\")\n",
        "    print(\"Βεβαιωθείτε ότι το Google Drive έχει συνδεθεί σωστά.\")\n",
        "\n",
        "try:\n",
        "    %cd {base_project_path}\n",
        "    print(f\"Βρίσκεστε τώρα στον φάκελο: {os.getcwd()}\")\n",
        "\n",
        "    folders = ['data_ingestion', 'nlp_processing', 'opportunity_identification', 'database', 'frontend', 'utils']\n",
        "    for folder in folders:\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "        init_file_path = os.path.join(folder, '__init__.py')\n",
        "        if not os.path.exists(init_file_path):\n",
        "            open(init_file_path, 'a').close()\n",
        "            print(f\"Δημιουργήθηκε φάκελος: {folder} και __init__.py\")\n",
        "        else:\n",
        "            print(f\"Φάκελος: {folder} και __init__.py υπάρχουν ήδη.\")\n",
        "\n",
        "    root_files = ['main.py', 'config.py', 'requirements.txt', 'README.md']\n",
        "    for f_name in root_files:\n",
        "        if not os.path.exists(f_name):\n",
        "            open(f_name, 'a').close()\n",
        "            print(f\"Δημιουργήθηκε αρχείο: {f_name}\")\n",
        "        else:\n",
        "            print(f\"Αρχείο: {f_name} υπάρχει ήδη.\")\n",
        "\n",
        "    print(\"\\nΗ βασική δομή του project δημιουργήθηκε/επιβεβαιώθηκε επιτυχώς!\")\n",
        "except Exception as e:\n",
        "    print(f\"Αδυναμία μετάβασης στον φάκελο του project ή δημιουργίας δομής: {e}\")\n",
        "    print(\"Παρακαλώ, ελέγξτε ξανά τη σύνδεση με το Google Drive και τη διαδρομή.\")"
      ],
      "metadata": {
        "id": "AokPwzaEegR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b318b9-b089-4ff6-cf64-1f07f2723b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Συνδέομαι με το Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Σύνδεση με το Google Drive ολοκληρώθηκε.\n",
            "Δημιουργήθηκε (ή υπάρχει ήδη) ο βασικός φάκελος project στο: /content/drive/My Drive/AI_Tax_Opportunity_Identifier\n",
            "/content/drive/My Drive/AI_Tax_Opportunity_Identifier\n",
            "Βρίσκεστε τώρα στον φάκελο: /content/drive/My Drive/AI_Tax_Opportunity_Identifier\n",
            "Φάκελος: data_ingestion και __init__.py υπάρχουν ήδη.\n",
            "Φάκελος: nlp_processing και __init__.py υπάρχουν ήδη.\n",
            "Φάκελος: opportunity_identification και __init__.py υπάρχουν ήδη.\n",
            "Φάκελος: database και __init__.py υπάρχουν ήδη.\n",
            "Φάκελος: frontend και __init__.py υπάρχουν ήδη.\n",
            "Φάκελος: utils και __init__.py υπάρχουν ήδη.\n",
            "Αρχείο: main.py υπάρχει ήδη.\n",
            "Αρχείο: config.py υπάρχει ήδη.\n",
            "Αρχείο: requirements.txt υπάρχει ήδη.\n",
            "Αρχείο: README.md υπάρχει ήδη.\n",
            "\n",
            "Η βασική δομή του project δημιουργήθηκε/επιβεβαιώθηκε επιτυχώς!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Εγκατάσταση Βασικών Βιβλιοθηκών & Ρύθμιση config.py"
      ],
      "metadata": {
        "id": "rLHQdtRRepMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys # Προσθήκη sys για χρήση του sys.path.insert\n",
        "\n",
        "# Βεβαιωθείτε ότι είστε στον φάκελο του project σας για να γίνει σωστά η εγκατάσταση και η καταγραφή\n",
        "base_project_path = '/content/drive/My Drive/AI_Tax_Opportunity_Identifier'\n",
        "%cd {base_project_path}\n",
        "\n",
        "# Εγκατάσταση βασικών βιβλιοθηκών\n",
        "print(\"Εγκαθιστώ τις βασικές βιβλιοθήκες...\")\n",
        "!pip install requests beautifulsoup4 lxml pandas spacy streamlit pyngrok\n",
        "\n",
        "# Κατέβασμα του ελληνικού spacy μοντέλου\n",
        "print(\"Κατεβάζω το ελληνικό μοντέλο της Spacy...\")\n",
        "try:\n",
        "    !python -m spacy download el_core_news_sm\n",
        "except Exception as e:\n",
        "    print(f\"Πρόβλημα κατά το κατέβασμα του μοντέλου el_core_news_sm (ίσως υπάρχει ήδη): {e}\")\n",
        "\n",
        "print(\"\\nΟι βασικές βιβλιοθήκες εγκαταστάθηκαν και το μοντέλο κατέβηκε επιτυχώς (ή υπήρχε)! \")\n",
        "\n",
        "# Δημιουργία περιεχομένου για το λιτό requirements.txt\n",
        "lite_requirements_content = \"\"\"\n",
        "requests\n",
        "beautifulsoup4\n",
        "pandas\n",
        "spacy\n",
        "streamlit\n",
        "pyngrok\n",
        "\"\"\"\n",
        "requirements_file_path = os.path.join(base_project_path, 'requirements.txt')\n",
        "with open(requirements_file_path, 'w') as f:\n",
        "    f.write(lite_requirements_content.strip())\n",
        "print(f\"Το αρχείο {requirements_file_path} ενημερώθηκε με τις λιτές απαιτήσεις.\")\n",
        "\n",
        "\n",
        "# Δημιουργία περιεχομένου για το config.py (χωρίς σχόλια και με CAPITAL_NEWS_URL)\n",
        "config_content = \"\"\"\n",
        "GOV_GAZETTE_BASE_URL = \"https://www.et.gr\"\n",
        "GOV_GAZETTE_SEARCH_URL = \"https://search.et.gr/el/\"\n",
        "MINISTRY_FINANCE_NEWS_URL = \"https://www.minfin.gr/news\"\n",
        "AADE_NEWS_URL = \"https://www.aade.gr/deltia-typoy-anakoinoseis\"\n",
        "NAFTEMPORIKI_TAX_URL = \"https://www.naftemporiki.gr/finance/tax/\"\n",
        "KATHIMERINI_ECONOMY_URL = \"https://www.kathimerini.gr/economy/\"\n",
        "CAPITAL_NEWS_URL = \"https://www.capital.gr/epikairotita\"\n",
        "TAX_KEYWORDS = [\n",
        "    \"φορολογία\", \"φορολογικές αλλαγές\", \"φορολογικός νόμος\", \"φορολογικές διατάξεις\",\n",
        "    \"ΦΠΑ\", \"εισόδημα\", \"ακίνητα\", \"κεφάλαιο\", \"ΑΑΔΕ\", \"φορολογικός έλεγχος\",\n",
        "    \"παράταση\", \"τροποποίηση\", \"νέο νομοσχέδιο\", \"κίνητρα\", \"επιδοτήσεις\",\n",
        "    \"φορολογικές δηλώσεις\", \"ηλεκτρονικά βιβλία\", \"mydata\",\n",
        "    \"διπλογραφικά\", \"λογιστικά\", \"κώδικας φορολογίας\"\n",
        "]\n",
        "DATABASE_NAME = \"tax_opportunities.db\"\n",
        "USER_AGENT = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\"\n",
        "HEADERS = {'User-Agent': USER_AGENT}\n",
        "\"\"\"\n",
        "\n",
        "# Γράψτε το περιεχόμενο στο config.py\n",
        "config_file_path = os.path.join(base_project_path, 'config.py')\n",
        "with open(config_file_path, 'w') as f:\n",
        "    f.write(config_content.strip())\n",
        "print(f\"Το αρχείο {config_file_path} ενημερώθηκε με τις ρυθμίσεις.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiT3B6tXeqvC",
        "outputId": "f4473aa5-8e86-4faa-da8f-f408f34b03a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/AI_Tax_Opportunity_Identifier\n",
            "Εγκαθιστώ τις βασικές βιβλιοθήκες...\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.12)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.45.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Κατεβάζω το ελληνικό μοντέλο της Spacy...\n",
            "Collecting el-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/el_core_news_sm-3.8.0/el_core_news_sm-3.8.0-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('el_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "Οι βασικές βιβλιοθήκες εγκαταστάθηκαν και το μοντέλο κατέβηκε επιτυχώς (ή υπήρχε)! \n",
            "Το αρχείο /content/drive/My Drive/AI_Tax_Opportunity_Identifier/requirements.txt ενημερώθηκε με τις λιτές απαιτήσεις.\n",
            "Το αρχείο /content/drive/My Drive/AI_Tax_Opportunity_Identifier/config.py ενημερώθηκε με τις ρυθμίσεις.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SCRAPPER CALL"
      ],
      "metadata": {
        "id": "X3Nc30kTfdP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Enable auto-reloading of modules (crucial for changes to .py files)\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Ensure you are in the project's root folder\n",
        "base_project_path = '/content/drive/My Drive/AI_Tax_Opportunity_Identifier'\n",
        "%cd {base_project_path}\n",
        "\n",
        "# Add the project root to the PATH for module discovery\n",
        "if base_project_path not in sys.path:\n",
        "    sys.path.insert(0, base_project_path)\n",
        "\n",
        "# Import and execute the scraper\n",
        "# Due to %autoreload, the latest changes from legislative_scraper.py and config.py will be loaded\n",
        "from data_ingestion import legislative_scraper\n",
        "\n",
        "print(\"\\n--- Running the Legislative News Scraper from MinFin and AADE ---\")\n",
        "latest_legislative_news_df = legislative_scraper.get_latest_legislative_news()\n",
        "\n",
        "if not latest_legislative_news_df.empty:\n",
        "    print(\"\\nLegislative News Results:\")\n",
        "    display(latest_legislative_news_df.head(10)) # Display the first 10 results\n",
        "    print(f\"\\nTotal {len(latest_legislative_news_df)} entries found.\")\n",
        "else:\n",
        "    print(\"\\nScraper found no data or failed to parse it.\")\n",
        "    print(\"Possible causes: Changes in website structure (selectors need updating) or temporary network issues.\")\n",
        "    print(\"Note: The search.et.gr/el/ website loads content dynamically with JavaScript. This scraper does not fully support it.\")"
      ],
      "metadata": {
        "id": "Jr2wMrjZffwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DBManager CALL"
      ],
      "metadata": {
        "id": "_4KPs4kOnt3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Ενεργοποίηση αυτόματης επαναφόρτωσης modules (κρίσιμο για αλλαγές σε .py αρχεία)\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Βεβαιωθείτε ότι είστε στον ριζικό φάκελο του project\n",
        "base_project_path = '/content/drive/My Drive/AI_Tax_Opportunity_Identifier'\n",
        "%cd {base_project_path}\n",
        "\n",
        "# Προσθήκη του ριζικού φακέλου στο PATH για να βρίσκει τα modules\n",
        "if base_project_path not in sys.path:\n",
        "    sys.path.insert(0, base_project_path)\n",
        "\n",
        "# Εισαγωγή των Scraper και DBManager\n",
        "from data_ingestion import legislative_scraper\n",
        "from database.db_manager import DBManager # <-- Νέα εισαγωγή!\n",
        "\n",
        "print(\"\\n--- Εκτελώ τον Scraper & Αποθηκεύω Δεδομένα στη Βάση Δεδομένων ---\")\n",
        "\n",
        "# 1. Εκτέλεση του Scraper\n",
        "latest_legislative_news_df = legislative_scraper.get_latest_legislative_news()\n",
        "\n",
        "# 2. Αποθήκευση δεδομένων στη βάση δεδομένων\n",
        "if not latest_legislative_news_df.empty:\n",
        "    db_manager = DBManager()\n",
        "    db_manager.connect()\n",
        "    db_manager.create_table() # Δημιουργία πίνακα αν δεν υπάρχει\n",
        "\n",
        "    print(\"\\nΠροσπαθώ να εισάγω τα νέα δεδομένα στη βάση δεδομένων...\")\n",
        "    db_manager.insert_opportunities(latest_legislative_news_df)\n",
        "\n",
        "    # 3. Ανάκτηση και εμφάνιση όλων των δεδομένων από τη βάση\n",
        "    print(\"\\nΌλα τα δεδομένα που υπάρχουν τώρα στη βάση δεδομένων:\")\n",
        "    all_stored_data_df = db_manager.fetch_all_opportunities()\n",
        "    if not all_stored_data_df.empty:\n",
        "        display(all_stored_data_df.head(10)) # Εμφάνιση των πρώτων 10 από τη βάση\n",
        "        print(f\"\\nΣυνολικά {len(all_stored_data_df)} καταχωρήσεις βρίσκονται στη βάση δεδομένων.\")\n",
        "    else:\n",
        "        print(\"Δεν βρέθηκαν καταχωρήσεις στη βάση δεδομένων.\")\n",
        "\n",
        "    db_manager.close()\n",
        "\n",
        "else:\n",
        "    print(\"\\nΔεν βρέθηκαν νέα από τους scrapers για αποθήκευση.\")\n",
        "\n",
        "print(\"\\nΗ διαδικασία ολοκληρώθηκε.\")"
      ],
      "metadata": {
        "id": "aruN90OWny2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nlp_processor CALL"
      ],
      "metadata": {
        "id": "WJfFPcJTvPNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Ενεργοποίηση αυτόματης επαναφόρτωσης modules (κρίσιμο για αλλαγές σε .py αρχεία)\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Βεβαιωθείτε ότι είστε στον ριζικό φάκελο του project\n",
        "base_project_path = '/content/drive/My Drive/AI_Tax_Opportunity_Identifier'\n",
        "%cd {base_project_path}\n",
        "\n",
        "# Προσθήκη του ριζικού φακέλου στο PATH για να βρίσκει τα modules\n",
        "if base_project_path not in sys.path:\n",
        "    sys.path.insert(0, base_project_path)\n",
        "\n",
        "# Εισαγωγή των Scraper, DBManager και NLPProcessor\n",
        "from data_ingestion import legislative_scraper\n",
        "from database.db_manager import DBManager\n",
        "from nlp_processing.nlp_processor import NLPProcessor # <-- Νέα εισαγωγή!\n",
        "\n",
        "print(\"\\n--- Εκτελώ τον Scraper, NLP Processor & Αποθηκεύω Δεδομένα στη Βάση Δεδομένων ---\")\n",
        "\n",
        "# 1. Εκτέλεση του Scraper\n",
        "latest_legislative_news_df = legislative_scraper.get_latest_legislative_news()\n",
        "\n",
        "# 2. Επεξεργασία δεδομένων με NLP\n",
        "if not latest_legislative_news_df.empty:\n",
        "    try:\n",
        "        nlp_processor = NLPProcessor()\n",
        "        print(\"\\nΕπεξεργάζομαι τα συλλεχθέντα νέα με NLP...\")\n",
        "        processed_df = nlp_processor.process_dataframe(latest_legislative_news_df)\n",
        "        print(\"Η επεξεργασία NLP ολοκληρώθηκε.\")\n",
        "\n",
        "        # 3. Αποθήκευση NLP αποτελεσμάτων στη βάση δεδομένων\n",
        "        db_manager = DBManager()\n",
        "        db_manager.connect()\n",
        "        db_manager.create_table() # Δημιουργία πίνακα αν δεν υπάρχει\n",
        "\n",
        "        # Εισάγουμε τα δεδομένα με τα νέα πεδία NLP.\n",
        "        # Θα χρειαστεί να ενημερώσουμε τη συνάρτηση insert_opportunities\n",
        "        # για να δέχεται και τα νέα NLP πεδία.\n",
        "        # Προς το παρόν, θα τα εισάγουμε μόνο αν υπάρχουν οι στήλες.\n",
        "\n",
        "        # Ενημέρωση: Η insert_opportunities έχει τροποποιηθεί για να εισάγει\n",
        "        # μόνο τα αρχικά πεδία. Θα χρειαστεί να την αναβαθμίσουμε αργότερα\n",
        "        # για να χειρίζεται τα NLP πεδία.\n",
        "        # Για να δείξουμε τα NLP αποτελέσματα, θα τα εμφανίσουμε απευθείας εδώ.\n",
        "\n",
        "        # Εισαγωγή των αρχικών δεδομένων στη βάση.\n",
        "        db_manager.insert_opportunities(processed_df) # Θα εισάγει μόνο τις στήλες που αναγνωρίζει\n",
        "\n",
        "        # Ενημέρωση: Ας δημιουργήσουμε μια νέα μέθοδο για να κάνουμε update τα NLP πεδία\n",
        "        # ή να εισάγουμε όλα τα πεδία από την αρχή αν ο πίνακας υποστηρίζει null.\n",
        "        # Για απλότητα, ας κάνουμε μια απλή εισαγωγή.\n",
        "\n",
        "        # Ανάκτηση και εμφάνιση όλων των δεδομένων από τη βάση, συμπεριλαμβανομένων των NLP πεδίων\n",
        "        print(\"\\nΌλα τα δεδομένα που υπάρχουν τώρα στη βάση δεδομένων (με NLP πεδία):\")\n",
        "        all_stored_data_df = db_manager.fetch_all_opportunities()\n",
        "        if not all_stored_data_df.empty:\n",
        "            # Εμφάνιση των NLP πεδίων αν υπάρχουν\n",
        "            display_columns = ['title', 'date', 'source', 'keywords', 'entities', 'main_topic', 'url']\n",
        "            # Εμφανίζουμε μόνο τις στήλες που υπάρχουν στο DataFrame\n",
        "            display(all_stored_data_df[ [col for col in display_columns if col in all_stored_data_df.columns] ].head(10))\n",
        "            print(f\"\\nΣυνολικά {len(all_stored_data_df)} καταχωρήσεις βρίσκονται στη βάση δεδομένων.\")\n",
        "        else:\n",
        "            print(\"Δεν βρέθηκαν καταχωρήσεις στη βάση δεδομένων.\")\n",
        "\n",
        "        db_manager.close()\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Δεν ήταν δυνατή η εκτέλεση του NLPProcessor: {e}\")\n",
        "        print(\"Βεβαιωθείτε ότι το ελληνικό μοντέλο spaCy έχει κατέβει και φορτωθεί σωστά.\")\n",
        "else:\n",
        "    print(\"\\nΔεν βρέθηκαν νέα από τους scrapers για αποθήκευση.\")\n",
        "\n",
        "print(\"\\nΗ διαδικασία ολοκληρώθηκε.\")"
      ],
      "metadata": {
        "id": "FGyutlvTvWOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "opportunity_identifier.py CALL"
      ],
      "metadata": {
        "id": "XKFNwep_yyjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd # <-- Add this line!\n",
        "\n",
        "# Ενεργοποίηση αυτόματης επαναφόρτωσης modules (κρίσιμο για αλλαγές σε .py αρχεία)\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Βεβαιωθείτε ότι είστε στον ριζικό φάκελο του project\n",
        "base_project_path = '/content/drive/My Drive/AI_Tax_Opportunity_Identifier'\n",
        "%cd {base_project_path}\n",
        "\n",
        "# Προσθήκη του ριζικού φακέλου στο PATH για να βρίσκει τα modules\n",
        "if base_project_path not in sys.path:\n",
        "    sys.path.insert(0, base_project_path)\n",
        "\n",
        "# Εισαγωγή των Scraper, DBManager, NLPProcessor και OpportunityIdentifier\n",
        "from data_ingestion import legislative_scraper\n",
        "from database.db_manager import DBManager\n",
        "from nlp_processing.nlp_processor import NLPProcessor\n",
        "from opportunity_identification.opportunity_identifier import OpportunityIdentifier\n",
        "\n",
        "print(\"\\n--- Εκτελώ τον Scraper, NLP Processor, Opportunity Identifier & Αποθηκεύω Δεδομένα στη Βάση Δεδομένων ---\")\n",
        "\n",
        "# 1. Εκτέλεση του Scraper\n",
        "latest_legislative_news_df = legislative_scraper.get_latest_legislative_news()\n",
        "\n",
        "# 2. Επεξεργασία δεδομένων με NLP\n",
        "processed_df = pd.DataFrame() # Αρχικοποίηση για περίπτωση που δεν βρεθούν νέα\n",
        "if not latest_legislative_news_df.empty:\n",
        "    try:\n",
        "        nlp_processor = NLPProcessor()\n",
        "        print(\"\\nΕπεξεργάζομαι τα συλλεχθέντα νέα με NLP...\")\n",
        "        processed_df = nlp_processor.process_dataframe(latest_legislative_news_df)\n",
        "        print(\"Η επεξεργασία NLP ολοκληρώθηκε.\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Δεν ήταν δυνατή η εκτέλεση του NLPProcessor: {e}\")\n",
        "        print(\"Βεβαιωθείτε ότι το ελληνικό μοντέλο spaCy έχει κατέβει και φορτωθεί σωστά.\")\n",
        "else:\n",
        "    print(\"\\nΔεν βρέθηκαν νέα από τους scrapers για επεξεργασία.\")\n",
        "\n",
        "# 3. Αναγνώριση και Βαθμολόγηση Ευκαιριών\n",
        "identified_opportunities_df = pd.DataFrame() # Αρχικοποίηση\n",
        "if not processed_df.empty:\n",
        "    try:\n",
        "        opportunity_identifier = OpportunityIdentifier()\n",
        "        print(\"\\nΑναγνωρίζω και βαθμολογώ τις ευκαιρίες...\")\n",
        "        identified_opportunities_df = opportunity_identifier.identify_and_score_opportunities(processed_df)\n",
        "        print(f\"Η αναγνώριση ευκαιριών ολοκληρώθηκε. Βρέθηκαν {len(identified_opportunities_df)} ευκαιρίες.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Σφάλμα κατά την εκτέλεση του OpportunityIdentifier: {e}\")\n",
        "else:\n",
        "    print(\"\\nΔεν υπάρχουν επεξεργασμένα δεδομένα για αναγνώριση ευκαιριών.\")\n",
        "\n",
        "\n",
        "# 4. Αποθήκευση NLP και Ευκαιριών στη βάση δεδομένων\n",
        "db_manager = DBManager()\n",
        "db_manager.connect()\n",
        "db_manager.create_table() # Δημιουργία πίνακα αν δεν υπάρχει\n",
        "\n",
        "if not processed_df.empty:\n",
        "    # Εισαγωγή/ενημέρωση των δεδομένων (με τα NLP και Opportunity πεδία)\n",
        "    for col in ['opportunity_score', 'opportunity_type']:\n",
        "        if col not in processed_df.columns:\n",
        "            processed_df[col] = None # Ή κάποια default τιμή\n",
        "\n",
        "    db_manager.insert_opportunities(processed_df)\n",
        "else:\n",
        "    print(\"\\nΔεν υπάρχουν δεδομένα για εισαγωγή/ενημέρωση στη βάση δεδομένων.\")\n",
        "\n",
        "\n",
        "# 5. Ανάκτηση και εμφάνιση όλων των δεδομένων από τη βάση, συμπεριλαμβανομένων των NLP και Opportunity πεδίων\n",
        "print(\"\\nΌλα τα δεδομένα που υπάρχουν τώρα στη βάση δεδομένων (με NLP & Opportunity πεδία):\")\n",
        "all_stored_data_df = db_manager.fetch_all_opportunities()\n",
        "if not all_stored_data_df.empty:\n",
        "    # Εμφάνιση των πιο σχετικών στηλών και των 10 κορυφαίων ευκαιριών\n",
        "    display_columns = ['title', 'date', 'source', 'opportunity_score', 'opportunity_type', 'keywords', 'entities', 'main_topic', 'url']\n",
        "\n",
        "    # Φιλτράρουμε για να εμφανίσουμε μόνο τις πραγματικές ευκαιρίες (score > 0)\n",
        "    # και ταξινομούμε με βάση τη βαθμολογία\n",
        "    display_opportunities = all_stored_data_df[all_stored_data_df['opportunity_score'] > 0].copy()\n",
        "    display_opportunities = display_opportunities.sort_values(by='opportunity_score', ascending=False)\n",
        "\n",
        "    print(f\"\\nΚορυφαίες {min(10, len(display_opportunities))} εντοπισμένες ευκαιρίες:\")\n",
        "    display(display_opportunities[[col for col in display_columns if col in display_opportunities.columns]].head(10))\n",
        "\n",
        "    print(f\"\\nΣυνολικά {len(all_stored_data_df)} καταχωρήσεις βρίσκονται στη βάση δεδομένων.\")\n",
        "else:\n",
        "    print(\"Δεν βρέθηκαν καταχωρήσεις στη βάση δεδομένων.\")\n",
        "\n",
        "db_manager.close()\n",
        "\n",
        "print(\"\\nΗ διαδικασία ολοκληρώθηκε.\")"
      ],
      "metadata": {
        "id": "vJhAbKzgy2eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GUI INTEFRACE"
      ],
      "metadata": {
        "id": "kJ4hu5fKJIVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "import importlib\n",
        "\n",
        "# Kill any existing ngrok tunnels to ensure a clean start\n",
        "ngrok.kill()\n",
        "\n",
        "# Enable auto-reloading of modules (crucial for changes in .py files)\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Ensure you are in the project's root folder\n",
        "base_project_path = '/content/drive/My Drive/AI_Tax_Opportunity_Identifier'\n",
        "%cd {base_project_path}\n",
        "\n",
        "# Add the project root to the PATH for module discovery\n",
        "if base_project_path not in sys.path:\n",
        "    sys.path.insert(0, base_project_path)\n",
        "\n",
        "# --- NGROK AUTH TOKEN SETUP ---\n",
        "# Replace with your ngrok Auth Token!\n",
        "NGROK_AUTH_TOKEN = \"2zdb0P1e0tz0Tb9wBgTAUekadSJ_5XnMjHLBbZq4Ah2Z6ysFM\" # <-- ΒΑΛΤΕ ΤΟ ΔΙΚΟ ΣΑΣ NGROK TOKEN ΕΔΩ!\n",
        "\n",
        "try:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"ngrok Auth Token ρυθμίστηκε.\")\n",
        "    if ngrok.get_default().authtoken_from_file():\n",
        "        print(\"ngrok token loaded from file successfully.\")\n",
        "    else:\n",
        "        print(\"Warning: ngrok token might not be persistently saved.\")\n",
        "except Exception as e:\n",
        "    print(f\"Σφάλμα κατά τη ρύθμιση του ngrok Auth Token: {e}\")\n",
        "    print(\"Βεβαιωθείτε ότι το token είναι σωστό.\")\n",
        "\n",
        "# --- START STREAMLIT APPLICATION ---\n",
        "print(\"\\nΕκκινώ την εφαρμογή Streamlit...\")\n",
        "\n",
        "streamlit_app_path = os.path.join(base_project_path, 'frontend', 'app.py')\n",
        "\n",
        "# Start Streamlit in a background process using 'python -m streamlit run'\n",
        "# This is a more robust way to launch Streamlit from a script.\n",
        "with open(\"streamlit_output.log\", \"w\") as outfile, open(\"streamlit_error.log\", \"w\") as errfile:\n",
        "    process = subprocess.Popen(\n",
        "        [sys.executable, \"-m\", \"streamlit\", \"run\", streamlit_app_path, \"--server.port\", \"8501\", \"--server.enableCORS\", \"false\", \"--server.enableXsrfProtection\", \"false\"],\n",
        "        stdout=outfile,\n",
        "        stderr=errfile\n",
        "    )\n",
        "\n",
        "# Give Streamlit more time to start\n",
        "print(\"Περιμένω 20 δευτερόλεπτα για να ξεκινήσει το Streamlit...\")\n",
        "time.sleep(20)\n",
        "\n",
        "# Create ngrok tunnel\n",
        "try:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"\\nΗ εφαρμογή Streamlit είναι διαθέσιμη στο: {public_url}\")\n",
        "    print(\"Ανοίξτε αυτό το URL στον browser σας για να δείτε το dashboard.\")\n",
        "except Exception as e:\n",
        "    print(f\"Σφάλμα κατά της δημιουργίας του ngrok tunnel: {e}\")\n",
        "    print(\"Βεβαιωθείτε ότι το ngrok Auth Token είναι σωστό και ότι το Streamlit ξεκίνησε.\")\n",
        "    print(\"Ελέγξτε τα αρχεία 'streamlit_output.log' και 'streamlit_error.log' στον φάκελο του project για λεπτομέρειες.\")\n",
        "\n",
        "    error_log_path = os.path.join(base_project_path, \"streamlit_error.log\")\n",
        "    if os.path.exists(error_log_path):\n",
        "        with open(error_log_path, \"r\") as f:\n",
        "            print(\"\\n--- Streamlit Error Log ---\")\n",
        "            print(f.read())\n",
        "            print(\"--- End Streamlit Error Log ---\")\n",
        "\n",
        "\n",
        "print(\"\\nΗ εκτέλεση του κελιού ολοκληρώθηκε. Η εφαρμογή Streamlit τρέχει στο παρασκήνιο.\")\n",
        "print(\"Για να σταματήσετε την εφαρμογή, κάντε 'Interrupt execution' σε αυτό το κελί.\")\n",
        "print(\"Για να δείτε τα logs, ελέγξτε τα αρχεία 'streamlit_output.log' και 'streamlit_error.log'.\")\n"
      ],
      "metadata": {
        "id": "h8nDwZIwJKMn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
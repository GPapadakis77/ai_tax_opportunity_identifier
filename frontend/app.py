import streamlit as st
import pandas as pd
import os
import sys
import importlib
from datetime import datetime, date
import requests
import json
import re
import time # <-- Î‘Î Î‘Î¡Î‘Î™Î¤Î—Î¤Î— Î Î¡ÎŸÎ£Î˜Î—ÎšÎ—

# --- Project Root Setup ---
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# --- Module Imports and Initialization ---
try:
    # These imports assume you have local files with these names.
    # If the app is a single file, you might not need these.
    import config
    importlib.reload(config)
    from data_ingestion import legislative_scraper
    importlib.reload(legislative_scraper)
    from nlp_processing import nlp_processor
    importlib.reload(nlp_processor)
    from database import db_manager
    importlib.reload(db_manager)
    from opportunity_identification import opportunity_identifier
    importlib.reload(opportunity_identifier)

    db_manager_instance = db_manager.DBManager()
    nlp_processor_instance = nlp_processor.NLPProcessor()
    opportunity_identifier_instance = opportunity_identifier.OpportunityIdentifier()

except Exception as e:
    # This error will show if the local files (config.py, etc.) are not found.
    st.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ· Ï„Ï‰Î½ ÎµÎ½Î¿Ï„Î®Ï„Ï‰Î½: {e}")
    st.info("Î’ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± .py (config, legislative_scraper, Îº.Î»Ï€.) Î²ÏÎ¯ÏƒÎºÎ¿Î½Ï„Î±Î¹ ÏƒÏ„Î¿Î½ ÏƒÏ‰ÏƒÏ„ÏŒ ÎºÎ±Ï„Î¬Î»Î¿Î³Î¿.")
    st.stop()

st.set_page_config(layout="wide", page_title="AI Product Opportunity Identifier")

# --- Core Application Functions ---

def run_pipeline():
    """Scrapes, processes, and stores new opportunity data."""
    with st.spinner("Î•ÎºÏ„ÎµÎ»ÎµÎ¯Ï„Î±Î¹ Î· Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î± ÏƒÏ…Î»Î»Î¿Î³Î®Ï‚ & Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½... Î‘Ï…Ï„ÏŒ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î´Î¹Î±ÏÎºÎ­ÏƒÎµÎ¹ Î¼ÎµÏÎ¹ÎºÎ¬ Î»ÎµÏ€Ï„Î¬."):
        latest_legislative_news_df = legislative_scraper.get_latest_legislative_news(current_config=config, filter_by_current_date=False)

        processed_df = pd.DataFrame()
        if not latest_legislative_news_df.empty:
            processed_df = nlp_processor_instance.process_dataframe(latest_legislative_news_df)
        
        identified_opportunities_df = pd.DataFrame()
        if not processed_df.empty:
            identified_opportunities_df = opportunity_identifier_instance.identify_and_score_opportunities(processed_df)

        db_manager_instance.connect()
        db_manager_instance.create_table()
        if not identified_opportunities_df.empty:
            db_manager_instance.insert_opportunities(identified_opportunities_df)
        db_manager_instance.close()

    st.success("Î— Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î± Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ! Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Î½Î±Î½ÎµÏÎ¸Î·ÎºÎ±Î½.")
    return identified_opportunities_df

# â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
# --- Î‘Î›Î›Î‘Î“Î— 1: Î— Î£Î¥ÎÎ‘Î¡Î¤Î—Î£Î— Î‘ÎÎ¤Î™ÎšÎ‘Î¤Î‘Î£Î¤Î‘Î˜Î—ÎšÎ• ÎœÎ• Î¤Î— Î£Î©Î£Î¤Î—, Î Î™ÎŸ Î£Î¤Î‘Î˜Î•Î¡Î— Î•ÎšÎ”ÎŸÎ£Î— ---
def generate_gemini_response(chat_history, api_key, context_str):
    """Generates a response from the Gemini API with a retry mechanism and context."""
    if not api_key:
        return "Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÎ¹ÏƒÎ±Î³Î¬Î³ÎµÏ„Îµ Ï„Î¿ Gemini API Key ÏƒÎ±Ï‚ ÏƒÏ„Î·Î½ Ï€Î»Î±ÏŠÎ½Î® Î¼Ï€Î¬ÏÎ±."

    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}"
    
    headers = {"Content-Type": "application/json"}
    
    api_chat_history = chat_history.copy()
    last_user_message = api_chat_history.pop()
    
    contextual_prompt = (
        f"ÎœÎµ Î²Î¬ÏƒÎ· Ï„Î¿ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï€Î»Î±Î¯ÏƒÎ¹Î¿ (context), Î±Ï€Î¬Î½Ï„Î·ÏƒÎµ ÏƒÏ„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ· Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î·. Î‘Î½ Î· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î¿ Ï€Î»Î±Î¯ÏƒÎ¹Î¿, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï„Î· Î³ÎµÎ½Î¹ÎºÎ® ÏƒÎ¿Ï… Î³Î½ÏÏƒÎ·.\n"
        f"--- Î Î›Î‘Î™Î£Î™ÎŸ ---\n{context_str if context_str else 'Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ Ï€Î»Î±Î¯ÏƒÎ¹Î¿.'}\n--- Î¤Î•Î›ÎŸÎ£ Î Î›Î‘Î™Î£Î™ÎŸÎ¥ ---\n\n"
        f"Î•ÏÏÏ„Î·ÏƒÎ· Î§ÏÎ®ÏƒÏ„Î·: {last_user_message['parts'][0]['text']}"
    )
    api_chat_history.append({"role": "user", "parts": [{"text": contextual_prompt}]})

    payload = {
        "contents": api_chat_history,
        "generationConfig": {"temperature": 0.7, "maxOutputTokens": 1500}
    }

    for attempt in range(3):
        try:
            response = requests.post(api_url, headers=headers, data=json.dumps(payload), timeout=30)
            if response.status_code == 503:
                raise requests.exceptions.HTTPError(f"503 Server Error: Service Unavailable")
            response.raise_for_status()
            result = response.json()

            if result.get("candidates") and result["candidates"][0].get("content", {}).get("parts"):
                return result["candidates"][0]["content"]["parts"][0]["text"]
            else:
                return "Î›Î®Ï†Î¸Î·ÎºÎµ Î¼Î· Î±Î½Î±Î¼ÎµÎ½ÏŒÎ¼ÎµÎ½Î· Î±Ï€Î¬Î½Ï„Î·ÏƒÎ· Î±Ï€ÏŒ Ï„Î¿ API."

        except requests.exceptions.RequestException as e:
            if attempt < 2:
                print(f"Î‘Ï€ÏŒÏ€ÎµÎ¹ÏÎ± {attempt + 1} Î±Ï€Î­Ï„Ï…Ï‡Îµ: {e}. Î•Ï€Î±Î½Î¬Î»Î·ÏˆÎ· ÏƒÎµ 2 Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î±...")
                time.sleep(2)
            else:
                return f"Î— ÎºÎ»Î®ÏƒÎ· API Î±Ï€Î­Ï„Ï…Ï‡Îµ Î¼ÎµÏ„Î¬ Î±Ï€ÏŒ Ï€Î¿Î»Î»Î±Ï€Î»Î­Ï‚ Ï€ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹ÎµÏ‚: {e}."
    
    return "Î— Ï…Ï€Î·ÏÎµÏƒÎ¯Î± Ï„Î¿Ï… API Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î· Î¼ÎµÏ„Î¬ Î±Ï€ÏŒ Ï€Î¿Î»Î»Î±Ï€Î»Î­Ï‚ Ï€ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹ÎµÏ‚."
# â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²

# --- Main Streamlit UI ---

st.header("AI Product Opportunity Identifier ğŸ’¡")
st.markdown("Î‘Î½Î±ÎºÎ±Î»ÏÏ€Ï„Î¿Î½Ï„Î±Ï‚ Î½Î­ÎµÏ‚ ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚ ÏƒÏ„Î¿Ï…Ï‚ Ï†Î¿ÏÎ¿Î»Î¿Î³Î¹ÎºÎ¿ÏÏ‚ ÎºÎ±Î¹ Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¿ÏÏ‚ Ï„Î¿Î¼ÎµÎ¯Ï‚.")

# --- Sidebar ---
with st.sidebar:
    st.title("Î Î¯Î½Î±ÎºÎ±Ï‚ Î•Î»Î­Î³Ï‡Î¿Ï…")

    gemini_api_key = st.secrets.get("GEMINI_API_KEY")
    if not gemini_api_key:
        gemini_api_key = st.text_input("Î•Î¹ÏƒÎ±Î³Î¬Î³ÎµÏ„Îµ Ï„Î¿ Gemini API Key:", type="password", help="ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± Î²ÏÎµÎ¯Ï„Îµ Ï„Î¿ ÎºÎ»ÎµÎ¹Î´Î¯ ÏƒÎ±Ï‚ ÏƒÏ„Î¿ Google AI Studio.")
        if not gemini_api_key:
            st.warning("Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÎ¹ÏƒÎ±Î³Î¬Î³ÎµÏ„Îµ Ï„Î¿ ÎºÎ»ÎµÎ¹Î´Î¯ API Î³Î¹Î± Î½Î± ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î®ÏƒÎµÏ„Îµ Ï„Î¿ chatbot.")
        else:
            st.success("Î¤Î¿ ÎºÎ»ÎµÎ¹Î´Î¯ API Î´ÏŒÎ¸Î·ÎºÎµ.")
    else:
        st.success("Î¤Î¿ ÎºÎ»ÎµÎ¹Î´Î¯ API Ï†Î¿ÏÏ„ÏÎ¸Î·ÎºÎµ Î¼Îµ ÎµÏ€Î¹Ï„Ï…Ï‡Î¯Î±.")

    if st.button("Î‘Î½Î±Î½Î­Ï‰ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ & Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î•Ï…ÎºÎ±Î¹ÏÎ¹ÏÎ½", help="Î•ÎºÏ„ÎµÎ»Î­ÏƒÏ„Îµ Î¾Î±Î½Î¬ ÏŒÎ»Î· Ï„Î· Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î± Î³Î¹Î± Î½Î± Î²ÏÎµÎ¯Ï„Îµ Î½Î­ÎµÏ‚ ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚."):
        st.session_state['refresh_data'] = True

    st.markdown("---")
    st.subheader("Î£Ï‡ÎµÏ„Î¹ÎºÎ¬ Î¼Îµ Ï„Î·Î½ Î•Ï†Î±ÏÎ¼Î¿Î³Î®")
    st.info(
        "Î‘Ï…Ï„Î® Î· ÎµÏ†Î±ÏÎ¼Î¿Î³Î® ÏƒÏ…Î»Î»Î­Î³ÎµÎ¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± Ï†Î¿ÏÎ¿Î»Î¿Î³Î¹ÎºÎ­Ï‚ ÎºÎ±Î¹ Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ­Ï‚ ÎµÎ¹Î´Î®ÏƒÎµÎ¹Ï‚, Ï„Î¹Ï‚ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î¬Î¶ÎµÏ„Î±Î¹ Î¼Îµ NLP, "
        "ÎµÎ½Ï„Î¿Ï€Î¯Î¶ÎµÎ¹ Ï€Î¹Î¸Î±Î½Î­Ï‚ ÏƒÏ…Î¼Î²Î¿Ï…Î»ÎµÏ…Ï„Î¹ÎºÎ­Ï‚ ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚ ÎºÎ±Î¹ Ï„Î¹Ï‚ ÎµÎ¼Ï†Î±Î½Î¯Î¶ÎµÎ¹ ÏƒÎµ Î­Î½Î±Î½ Î´Î¹Î±Î´ÏÎ±ÏƒÏ„Î¹ÎºÏŒ Ï€Î¯Î½Î±ÎºÎ±."
    )
    if st.button("Î’Î¿Î®Î¸ÎµÎ¹Î± Î±Ï€ÏŒ Ï„Î¿ Chatbot ğŸ’¬", help="Î‘Î½Î¿Î¯Î¾Ï„Îµ Ï„Î¿ chat Î³Î¹Î± Î½Î± ÎºÎ¬Î½ÎµÏ„Îµ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚."):
        st.session_state['show_chatbot'] = not st.session_state.get('show_chatbot', False)
        st.rerun() # Added for smoother toggle
    st.markdown("---")

# --- Session State Initialization ---
if 'last_identified_df' not in st.session_state:
    st.session_state['last_identified_df'] = pd.DataFrame()
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []
if 'show_chatbot' not in st.session_state:
    st.session_state['show_chatbot'] = False
if 'refresh_data' not in st.session_state:
    st.session_state['refresh_data'] = False

# --- Data Loading Logic ---
if st.session_state.refresh_data:
    identified_opportunities_df = run_pipeline()
    st.session_state['last_identified_df'] = identified_opportunities_df
    st.session_state.chat_history = []
    st.session_state.refresh_data = False
    st.rerun()
else:
    if st.session_state.last_identified_df.empty:
        with st.spinner("Î¦ÏŒÏÏ„Ï‰ÏƒÎ· Î±ÏÏ‡Î¹ÎºÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ Ï„Î· Î²Î¬ÏƒÎ·..."):
            db_manager_instance.connect()
            all_stored_data_df = db_manager_instance.fetch_all_opportunities()
            db_manager_instance.close()

            if not all_stored_data_df.empty:
                identified_opportunities_df = all_stored_data_df[all_stored_data_df['opportunity_score'] > 0].copy()
                identified_opportunities_df = identified_opportunities_df.sort_values(by='opportunity_score', ascending=False)
            else:
                identified_opportunities_df = pd.DataFrame()
            st.session_state['last_identified_df'] = identified_opportunities_df
    else:
        identified_opportunities_df = st.session_state['last_identified_df']

# --- Display Identified Opportunities ---
st.subheader("Î•Ï€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ· Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼Î­Î½Ï‰Î½ Î•Ï…ÎºÎ±Î¹ÏÎ¹ÏÎ½")

if identified_opportunities_df.empty:
    st.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚. Î Î±Ï„Î®ÏƒÏ„Îµ 'Î‘Î½Î±Î½Î­Ï‰ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½' Î³Î¹Î± Î½Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÏ„Îµ.")
else:
    total_opportunities = len(identified_opportunities_df)
    st.info(f"Î•Î¼Ï†Î±Î½Î¯Î¶Î¿Î½Ï„Î±Î¹ {total_opportunities} ÎµÎ½Ï„Î¿Ï€Î¹ÏƒÎ¼Î­Î½ÎµÏ‚ ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚.")
    st.markdown("---")
    st.subheader("Î¦Î¯Î»Ï„ÏÎ± & Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½")
    
    search_query = st.text_input("Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î¼Îµ Î¤Î¯Ï„Î»Î¿ Î® Î›Î­Î¾ÎµÎ¹Ï‚-ÎšÎ»ÎµÎ¹Î´Î¹Î¬:", "")
    col_filter1, col_filter2 = st.columns(2)
    with col_filter1:
        unique_sources = ["ÎŒÎ»ÎµÏ‚"] + list(identified_opportunities_df['source'].unique())
        selected_source = st.selectbox("Î¦Î¯Î»Ï„ÏÎ¿ Î±Î½Î¬ Î Î·Î³Î®:", unique_sources)
    with col_filter2:
        unique_types = ["ÎŒÎ»Î¿Î¹"] + list(identified_opportunities_df['opportunity_type'].dropna().unique())
        selected_type = st.selectbox("Î¦Î¯Î»Ï„ÏÎ¿ Î±Î½Î¬ Î¤ÏÏ€Î¿ Î•Ï…ÎºÎ±Î¹ÏÎ¯Î±Ï‚:", unique_types)

    filtered_df = identified_opportunities_df.copy()
    if search_query:
        filtered_df = filtered_df[
            filtered_df['title'].str.contains(search_query, case=False, na=False) |
            filtered_df['keywords'].str.contains(search_query, case=False, na=False)
        ]
    if selected_source != "ÎŒÎ»ÎµÏ‚":
        filtered_df = filtered_df[filtered_df['source'] == selected_source]
    if selected_type != "ÎŒÎ»Î¿Î¹":
        filtered_df = filtered_df[filtered_df['opportunity_type'] == selected_type]

    if filtered_df.empty:
        st.info("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… Î½Î± Ï„Î±Î¹ÏÎ¹Î¬Î¶Î¿Ï…Î½ Î¼Îµ Ï„Î± ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½Î± Ï†Î¯Î»Ï„ÏÎ±.")
    else:
        display_cols = ['title', 'date', 'source', 'opportunity_score', 'opportunity_type', 'url', 'keywords', 'main_topic']
        st.dataframe(
            filtered_df[display_cols],
            use_container_width=True,
            hide_index=True,
            column_config={
                "url": st.column_config.LinkColumn("URL", display_text="Î£ÏÎ½Î´ÎµÏƒÎ¼Î¿Ï‚"),
                "date": st.column_config.DateColumn("Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±", format="DD/MM/YYYY"),
                "opportunity_score": st.column_config.NumberColumn("Î’Î±Î¸Î¼Î¿Î»Î¿Î³Î¯Î±", help="Î’Î±Î¸Î¼ÏŒÏ‚ Î£Î·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚ (Ï…ÏˆÎ·Î»ÏŒÏ„ÎµÏÎ¿Ï‚ = ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï‚)", format="%.1f"),
                "opportunity_type": "Î¤ÏÏ€Î¿Ï‚",
                "title": st.column_config.TextColumn("Î¤Î¯Ï„Î»Î¿Ï‚", width="large"),
            }
        )
        csv_data = filtered_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="Î›Î®ÏˆÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Ï‰Ï‚ CSV",
            data=csv_data,
            file_name="identified_opportunities.csv",
            mime="text/csv"
        )

st.markdown("---")

# --- Chatbot Interface ---
if st.session_state.show_chatbot:
    st.subheader("Î’Î¿Î·Î¸ÏŒÏ‚ Chatbot ğŸ’¬")
    st.markdown("Î¡Ï‰Ï„Î®ÏƒÏ„Îµ Î¼Îµ Î³Î¹Î± Ï„Î¹Ï‚ ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… ÎµÎ½Ï„Î¿Ï€Î¯ÏƒÏ„Î·ÎºÎ±Î½ Î® Î³Î¹Î± Î³ÎµÎ½Î¹ÎºÎ¬ Ï†Î¿ÏÎ¿Î»Î¿Î³Î¹ÎºÎ¬/Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹ÎºÎ¬ Î¸Î­Î¼Î±Ï„Î±!")
    
    if not st.session_state.chat_history:
        # â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
        # --- Î‘Î›Î›Î‘Î“Î— 2: ÎŸÎ™ ÎŸÎ”Î—Î“Î™Î•Î£ Î•Î“Î™ÎÎ‘Î Î Î™ÎŸ Î•ÎÎ¥Î ÎÎ•Î£ ---
        system_prompt = (
            "You are an expert AI assistant for Greek tax and economic topics. Your goal is to provide concise and helpful information. "
            "The user will provide you with context from a database along with their question. Base your answer primarily on this context. "
            "If the question is general and the answer is NOT in the context, then you are allowed to use your own general knowledge to provide an accurate answer."
        )
        # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²
        st.session_state.chat_history.append({"role": "user", "parts": [{"text": system_prompt}]})
        st.session_state.chat_history.append({"role": "model", "parts": [{"text": "ÎšÎ±Î»Î·ÏƒÏ€Î­ÏÎ±! Î•Î¯Î¼Î±Î¹ Î­Ï„Î¿Î¹Î¼Î¿Ï‚ Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÏ‰ ÏƒÏ„Î¹Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÎ±Ï‚."}]})

    for message in st.session_state.chat_history[2:]: # Display only user-facing messages
        with st.chat_message(message["role"]):
            st.markdown(message["parts"][0]["text"])
    
    st.markdown("---")
    st.markdown("**ÎšÎ¬Î½Ï„Îµ ÎºÎ»Î¹Îº ÏƒÎµ Î¼Î¹Î± ÎµÏÏÏ„Î·ÏƒÎ· Î³Î¹Î± Î½Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÏ„Îµ:**")
    
    suggested_questions = [
        "Î Î¿Î¹ÎµÏ‚ ÎµÎ¯Î½Î±Î¹ Î¿Î¹ Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯ÎµÏ‚ Î±Î»Î»Î±Î³Î­Ï‚ ÏƒÏ„Î· Ï†Î¿ÏÎ¿Î»Î¿Î³Î¹ÎºÎ® Î½Î¿Î¼Î¿Î¸ÎµÏƒÎ¯Î±;",
        "Î£Ï…Î½Î¿ÏˆÎ¯ÏƒÏ„Îµ Ï„Î¹Ï‚ ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„ÎµÏÎµÏ‚ ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚.",
        "Î ÎµÎ¯Ï„Îµ Î¼Î¿Ï… Î³Î¹Î± ÎµÏ…ÎºÎ±Î¹ÏÎ¯ÎµÏ‚ Ï€Î¿Ï… ÏƒÏ‡ÎµÏ„Î¯Î¶Î¿Î½Ï„Î±Î¹ Î¼Îµ ÎºÎ¯Î½Î·Ï„ÏÎ±."
    ]
    
    query_to_send = None
    cols = st.columns(len(suggested_questions))
    for i, question in enumerate(suggested_questions):
        if cols[i].button(question, key=f"suggested_q_{i}"):
            query_to_send = question
    
    if user_input := st.chat_input("Î— ÎµÏÏÏ„Î·ÏƒÎ® ÏƒÎ±Ï‚:"):
        query_to_send = user_input

    if query_to_send:
        st.session_state.chat_history.append({"role": "user", "parts": [{"text": query_to_send}]})
        
        with st.chat_message("user"):
            st.markdown(query_to_send)

        with st.chat_message("assistant"):
            with st.spinner("Î£ÎºÎ­Ï†Ï„Î¿Î¼Î±Î¹..."):
                # â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
                # --- Î‘Î›Î›Î‘Î“Î— 3: Î¤ÎŸ CONTEXT Î£Î¤Î•Î›ÎÎ•Î¤Î‘Î™ Î Î›Î•ÎŸÎ ÎœÎ• ÎšÎ‘Î˜Î‘Î¡ÎŸ Î¤Î¡ÎŸÎ ÎŸ ---
                context_df = filtered_df
                context_str = ""
                if not context_df.empty:
                    for _, row in context_df.head(10).iterrows():
                        context_str += f"- Î¤Î¯Ï„Î»Î¿Ï‚: {row.get('title', 'N/A')}, Î£ÎºÎ¿Ï: {row.get('opportunity_score', 0):.1f}\n"
                
                response_text = generate_gemini_response(st.session_state.chat_history, gemini_api_key, context_str)
                st.markdown(response_text)
                # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²
        
        st.session_state.chat_history.append({"role": "model", "parts": [{"text": response_text}]})
        st.rerun()